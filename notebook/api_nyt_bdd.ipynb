{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from datetime import datetime \n",
    "import random\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from dateutil import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5769\n",
      "Total for today 5769\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "year = 2023\n",
    "month = 3\n",
    "day = 4\n",
    "api = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key=K10EkuGSc2pswvCeoaYBZQyLQoRnTQFV\"\n",
    "\n",
    "def filter_by_day(list, day):\n",
    "\t\n",
    "\tresult = []\n",
    "\tfor article in list:\n",
    "\t\td = datetime.strptime(article[\"pub_date\"], \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\t\tif d.day == day:\n",
    "\t\t\tresult.append(article)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "response = requests.get(api)\n",
    "data = response.json()\n",
    "articles = data[\"response\"][\"docs\"]\n",
    "\n",
    "# First, get by day\n",
    "#articles = filter_by_day(articles, day)\n",
    "\n",
    "print(\"Total\",data[\"response\"][\"meta\"][\"hits\"])\n",
    "print(\"Total for today\", len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"04_03_2023_nyt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    'Créer un dataFrame des données utiles'\n",
    "    data1 = {'Titres': [],  \n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'abstract':[],\n",
    "        'source':[],\n",
    "        'web_url':[],\n",
    "        'categories':[],\n",
    "        'lead_paragraph':[],\n",
    "        'pub_date':[],\n",
    "        'keywords':[]\n",
    "        }\n",
    "    \n",
    "\n",
    "    for article in response: \n",
    "        data1['Titres'].append(article['headline']['main']) \n",
    "        data1['abstract'].append(article['abstract'])\n",
    "        data1['web_url'].append(article['web_url']) \n",
    "        data1['lead_paragraph'].append(article['lead_paragraph']) \n",
    "        data1['source'].append(article['source'])\n",
    "        data1['pub_date'].append(article[\"pub_date\"])  \n",
    "        data1['doc_type'].append(article['document_type'])\n",
    "        data1['categories'].append(article['section_name'])\n",
    "        data1['material_type'].append(article['type_of_material'])\n",
    "\n",
    "        #data1['sous_categories'].append(article['subsection_name'])\n",
    "        #data1[\"auteur\"].append(article[\"byline\"][\"person\"][0][\"firstname\"]+\" \"+article[\"byline\"][\"person\"][0][\"lastname\"])\n",
    "        keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "        data1['keywords'].append(keywords)\n",
    "        \n",
    "        df = pd.DataFrame(data1)\n",
    "\n",
    "        \n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = parse_response(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql://root:root@127.0.0.1:3306/nyt_bd\")\n",
    "dbConnection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_sql('nyt_article',con=engine,if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5769 entries, 0 to 5768\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype                  \n",
      "---  ------          --------------  -----                  \n",
      " 0   Titres          5769 non-null   object                 \n",
      " 1   doc_type        5769 non-null   object                 \n",
      " 2   material_type   5769 non-null   object                 \n",
      " 3   abstract        5769 non-null   object                 \n",
      " 4   source          5769 non-null   object                 \n",
      " 5   web_url         5769 non-null   object                 \n",
      " 6   categories      5769 non-null   object                 \n",
      " 7   lead_paragraph  5769 non-null   object                 \n",
      " 8   pub_date        5769 non-null   datetime64[ns, tzutc()]\n",
      "dtypes: datetime64[ns, tzutc()](1), object(8)\n",
      "memory usage: 405.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pub_date'] = df2['pub_date'].apply(lambda x: x[0:10])\n",
    "\n",
    "df_finale= df2.assign(key1 = df2['keywords'].apply(lambda x: x[0] if len(x)>0 else NAN))\\\n",
    "  .assign(key2 = df2['keywords'].apply(lambda x: x[1] if len(x)>1 else NAN))\\\n",
    "  .assign(key3 = df2['keywords'].apply(lambda x: x[2] if len(x)>2 else NAN))\\\n",
    "  .assign(key4 = df2['keywords'].apply(lambda x: x[3] if len(x)>3 else NAN))\\\n",
    "  .assign(key5 = df2['keywords'].apply(lambda x: x[4] if len(x)>4 else NAN))\\\n",
    "  .assign(key6 = df2['keywords'].apply(lambda x: x[5] if len(x)>5 else NAN))\\\n",
    "  .assign(key7 = df2['keywords'].apply(lambda x: x[6] if len(x)>6 else NAN))\\\n",
    "  .assign(key8 = df2['keywords'].apply(lambda x: x[7] if len(x)>7 else NAN))\\\n",
    "  .assign(key9 = df2['keywords'].apply(lambda x: x[8] if len(x)>8 else NAN))\\\n",
    "  .assign(key10 = df2['keywords'].apply(lambda x: x[9] if len(x)>9 else NAN))\\\n",
    "  .assign(id= df2.index)\n",
    "  \n",
    "df_finale.pop('keywords')\n",
    "\n",
    "\n",
    "df_keys=pd.wide_to_long(df_finale, \"key\", i=\"id\", j=\"keys\")\\\n",
    "  .dropna(subset=[\"key\"])\\\n",
    "  .groupby(['key','pub_date'])['Titres'].count().sort_values(ascending=False).reset_index(name='count')\\\n",
    "  .pivot(index=\"key\",columns=\"pub_date\", values=\"count\")\n",
    "\n",
    "\n",
    "df_categories=df_finale.groupby(['categories','pub_date'])['id'].count().sort_values(ascending=False).reset_index(name='count')\\\n",
    "  .pivot(index=\"categories\",columns=\"pub_date\", values=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories.fillna(0)\n",
    "df_keys.fillna(0)\n",
    "\n",
    "df_categories.to_sql('df_categories_art',con=engine,if_exists = \"replace\")\n",
    "df_keys.to_sql('df_keys_art',con=engine,if_exists = \"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9775c12e7ee0fd63cd5899aac483769471b18cea5dbb74f58b032f9912f316a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
